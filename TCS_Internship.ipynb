{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCS Internship.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GomNXAWbvhwo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "e2f345f7-a7b6-4baf-cf9e-11878f28ec38"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/UCSD\"\n",
        "%cd \"/content/drive/My Drive/UCSD\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/UCSD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJuM0vlBvuQg"
      },
      "source": [
        "!pip install keras_layer_normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNzHOKWuvxzg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "54296fe5-5ab6-4df4-b76f-e741f258eccd"
      },
      "source": [
        "from os import listdir\n",
        "import fnmatch\n",
        "from os.path import isfile, join, isdir\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "import keras\n",
        "from keras.layers import Conv2DTranspose,BatchNormalization, Conv2D,MaxPooling2D, UpSampling2D, Input,UpSampling3D,MaxPooling3D\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D,TimeDistributed, Conv2D\n",
        "from keras.layers import Conv3D,Conv3DTranspose\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "# from keras_layer_normalization import LayerNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "print(\"tf.__version__ is\", tf.__version__)\n",
        "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import moveaxis\n",
        "import keras.backend as K\n",
        "# from persistence1d import RunPersistence\n",
        "from scipy.signal import argrelextrema\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "from numpy import savez_compressed\n",
        "import shutil\n",
        "from numpy import load\n",
        "def _get_available_gpus():\n",
        "    if tfback._LOCAL_DEVICES is None:\n",
        "        devices = tf.config.list_logical_devices()\n",
        "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "tfback._get_available_gpus = _get_available_gpus\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from skimage.measure import compare_ssim\n",
        "from skimage.metrics import structural_similarity as ssim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tf.__version__ is 2.2.0\n",
            "tf.keras.__version__ is: 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iy_3WZf0sWd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d07598ab-136b-4ad8-fc2f-22f2d0d6473d"
      },
      "source": [
        "folder_name = str(input(\"Which folder do you want to test your results on?\\n\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Which folder do you want to test your results on?\n",
            "Test019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za0whAZtwWkw"
      },
      "source": [
        "train_path = path + '/UCSD_Anomaly_Dataset.v1p2'\n",
        "test_path = train_path + '/UCSDped1/Test/'+folder_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRmkqhDfwgvq"
      },
      "source": [
        "# **2D Convolutional Autoencoder with MSE loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEFCHWGVwaGP"
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98iMsvjWw11a"
      },
      "source": [
        "training_set = []\n",
        "for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "  if fnmatch.fnmatch(f,\"*ped*\"):\n",
        "    for g in listdir(join(Config.DATASET_PATH,f)):\n",
        "      if fnmatch.fnmatch(g,\"Train\"):\n",
        "        for c in listdir(join(join(Config.DATASET_PATH,f), g)):\n",
        "          if fnmatch.fnmatch(c,\"Train*\"):\n",
        "            all_frames = []\n",
        "            for j in listdir(join(join(join(Config.DATASET_PATH,f), g),c)):\n",
        "              if str(j)[-3:] == \"tif\":\n",
        "                img = Image.open(join(join(join(join(Config.DATASET_PATH,f), g),c), j)).resize((256, 256))\n",
        "                img = np.array(img, dtype=np.float16) / 255.0\n",
        "                all_frames.append(img)\n",
        "            # get the augmented images from the list of images after applying data augmentation\n",
        "            for stride in range(1, 4):\n",
        "              training_set.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUlvde7mw3TN"
      },
      "source": [
        "input_frm = Input(shape=(5, 256, 256))  \n",
        "\n",
        "#Encoder\n",
        "x = Conv2D(512, (11, 11),strides=4,activation='relu', padding='same',\n",
        "           kernel_initializer=keras.initializers.glorot_normal(),\n",
        "           data_format='channels_first')(input_frm)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "\n",
        "x = Conv2D(256, (5, 5), activation='relu', padding='same',\n",
        "           data_format='channels_first',\n",
        "           kernel_initializer=keras.initializers.glorot_normal())(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "\n",
        "encoded = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "                 data_format='channels_first',\n",
        "                 kernel_initializer=keras.initializers.glorot_normal())(x)\n",
        "\n",
        "#Decoder\n",
        "x = Conv2DTranspose(128, (3, 3), padding=\"same\",\n",
        "                    kernel_initializer=keras.initializers.glorot_normal(),\n",
        "                    activation='relu',\n",
        "                    data_format='channels_first')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2DTranspose(256, (3, 3), padding=\"same\",\n",
        "                    kernel_initializer=keras.initializers.glorot_normal(),\n",
        "                    activation='relu',\n",
        "                    data_format='channels_first')(x)\n",
        "x = BatchNormalization()(x)                    \n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2DTranspose(512, (5, 5), padding=\"same\",\n",
        "                    kernel_initializer=keras.initializers.glorot_normal(),\n",
        "                    activation='relu',\n",
        "                    data_format='channels_first')(x)\n",
        "\n",
        "decoded = Conv2DTranspose(5, (11, 11),strides=4, padding=\"same\",\n",
        "                          kernel_initializer=keras.initializers.glorot_normal(),\n",
        "                          activation='relu',\n",
        "                          data_format='channels_first')(x)\n",
        "\n",
        "\n",
        "conv2d_mse_autoencoder = Model(input_frm, decoded)\n",
        "conv2d_mse_autoencoder.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.0001), loss='mse')                          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYb3onNJyZ-r"
      },
      "source": [
        "training_set = np.array(training_set)\n",
        "training_set = training_set.reshape(-1,5,256,256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCen_nF2y-S8"
      },
      "source": [
        "history = conv2d_mse_autoencoder.fit(training_set,training_set,\n",
        "                                  epochs=50,\n",
        "                                  batch_size=32,\n",
        "                                  shuffle=True\n",
        "                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f0gckxazQQd"
      },
      "source": [
        "sz = 200\n",
        "test = np.zeros(shape=(sz, 256, 256))\n",
        "cnt = 0\n",
        "for f in sorted(listdir(test_path)):\n",
        "    if str(join(test_path, f))[-3:] == \"tif\":\n",
        "      img = Image.open(join(test_path,f)).resize((256, 256))\n",
        "      img = np.array(img, dtype=np.float16) / 256.0\n",
        "      test[cnt, :, :] = img\n",
        "      cnt = cnt + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pgBbDp0zTWi"
      },
      "source": [
        "sz = test.shape[0] - 5\n",
        "sequences = np.zeros((sz+1, 5, 256, 256))\n",
        "# apply the sliding window technique to get the sequences\n",
        "for i in range(0, sz+1):\n",
        "    clip = np.zeros((5, 256, 256))\n",
        "    for j in range(0, 5):\n",
        "        clip[j] = test[i + j, :, :]\n",
        "    sequences[i]=clip\n",
        "print(\"sequences shape:\",sequences.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uk9OdtWzhex"
      },
      "source": [
        "reconstructed_sequences = conv2d_mse_autoencoder.predict(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcvN5bmt0kT1"
      },
      "source": [
        "sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz+1)])\n",
        "sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "sr = 1.0 - sa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNOx5rX81qNG"
      },
      "source": [
        "plt.plot(sr)\n",
        "plt.title(folder_name)\n",
        "plt.xticks(np.arange(0, sz+1,10))\n",
        "plt.ylabel('regularity score Sr(t)')\n",
        "plt.xlabel('frame t')\n",
        "plt.grid(b=1,axis='both')\n",
        "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fFYH4rE1yMI"
      },
      "source": [
        "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "fps = 10\n",
        "file_name = 'conv2d_mse_'+folder_name+'.mp4'\n",
        "video_filename = file_name\n",
        "out = cv2.VideoWriter(video_filename, fourcc, fps, (256, 256))\n",
        "\n",
        "\n",
        "THRESH = 60\n",
        "THRESH_AREA = 50\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  input_frame,output_frame = sequences[i][0].copy(),reconstructed_sequences[i][0].copy()\n",
        "  (score, diff) = ssim(input_frame,output_frame, full=True)\n",
        "  diff = (diff * 255).astype(np.uint8)\n",
        "  ret,thresh = cv2.threshold(diff,THRESH,255,cv2.THRESH_BINARY_INV)\n",
        "  contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "\n",
        "  for c in contours:\n",
        "    area = cv2.contourArea(c)\n",
        "    if area > THRESH_AREA:\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "      cv2.rectangle(input_frame, (x, y), (x + w, y + h),1)\n",
        "  gray = cv2.normalize(input_frame, None, 255, 0,norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_8U)\n",
        "  gray_3c = cv2.merge([gray, gray,gray])\n",
        "  out.write(gray_3c)\n",
        "\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wThZ5i_k5x9p"
      },
      "source": [
        "# **2D Convolutional Autoencoder with SSIM loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mz2rpap55pE"
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(256, 256,sequence_size))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[:, :,cnt] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHvXw1636IRp"
      },
      "source": [
        "training_set = []\n",
        "for f in sorted(listdir(train_path)):\n",
        "  if fnmatch.fnmatch(f,\"*ped*\"):\n",
        "    for g in listdir(join(train_path,f)):\n",
        "      if fnmatch.fnmatch(g,\"Train\"):\n",
        "        for c in listdir(join(join(train_path,f), g)):\n",
        "          if fnmatch.fnmatch(c,\"Train*\"):\n",
        "            all_frames = []\n",
        "            for j in listdir(join(join(join(train_path,f), g),c)):\n",
        "              if str(j)[-3:] == \"tif\":\n",
        "                img = Image.open(join(join(join(join(train_path,f), g),c), j)).resize((256, 256))\n",
        "                img = np.array(img, dtype=np.float16) / 255.0\n",
        "                all_frames.append(img)\n",
        "            # get the augmented images from the list of images after applying data augmentation\n",
        "            for stride in range(1, 4):\n",
        "              training_set.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwT9jxMt6KrQ"
      },
      "source": [
        "input_frm = Input(shape=(256, 256,5))  \n",
        "\n",
        "#Encoder\n",
        "x = Conv2D(512, (11, 11),strides=4,activation='relu', padding='same',kernel_initializer=keras.initializers.glorot_normal())(input_frm)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2D(256, (5, 5), activation='relu', padding='same',kernel_initializer=keras.initializers.glorot_normal())(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "encoded = Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer=keras.initializers.glorot_normal())(x)\n",
        "\n",
        "#Decoder\n",
        "x = Conv2DTranspose(128, (3, 3), padding=\"same\",kernel_initializer=keras.initializers.glorot_normal(), activation='relu')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2DTranspose(256, (3, 3), padding=\"same\",kernel_initializer=keras.initializers.glorot_normal(),activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2DTranspose(512, (5, 5), padding=\"same\",kernel_initializer=keras.initializers.glorot_normal(),activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "output_frm = Conv2DTranspose(5, (11, 11),strides=4, padding=\"same\",kernel_initializer=keras.initializers.glorot_normal(),activation='relu')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR5rDW6h6R-i"
      },
      "source": [
        "def ssim(input_frm, decoded):\n",
        "    ssim_loss = tf.reduce_mean(tf.image.ssim(output_frm, input_frm, 1.0),axis=-1)\n",
        "    return 1- ssim_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTVvUyhN6mOq"
      },
      "source": [
        "conv2d_ssim_autoencoder = Model(input_frm,output_frm)\n",
        "conv2d_ssim_autoencoder.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.001), loss=ssim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pvf7dK37QIA"
      },
      "source": [
        "history = conv2d_ssim_autoencoder.fit(training_set,training_set,\n",
        "                          epochs=50,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEiE4wh6-D3G"
      },
      "source": [
        "sz = 200\n",
        "test = np.zeros(shape=(256, 256,sz))\n",
        "cnt = 0\n",
        "for f in sorted(listdir(test_path)):\n",
        "    if str(join(test_path, f))[-3:] == \"tif\":\n",
        "        img = Image.open(join(test_path, f)).resize((256, 256))\n",
        "        img = np.array(img, dtype=np.float32) / 256.0\n",
        "        test[:, :, cnt] = img\n",
        "        cnt = cnt + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF3t7JBFycqF"
      },
      "source": [
        "sz = test.shape[-1] - 5\n",
        "sequences = np.zeros((sz+1, 256,256,5))\n",
        "# apply the sliding window technique to get the sequences\n",
        "for i in range(0, sz+1):\n",
        "    clip = np.zeros((256,256,5))\n",
        "    clip = moveaxis(clip, 2, 0)\n",
        "    for j in range(0, 5):\n",
        "        clip[j] = test[:, :,i + j]\n",
        "    clip = moveaxis(clip, 0, 2)    \n",
        "    sequences[i] = clip\n",
        "print(\"sequences shape:\",sequences.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rARpK5zo-Kma"
      },
      "source": [
        "reconstructed_sequences = autoencoder.predict(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS5n7H3K7ZKJ"
      },
      "source": [
        "sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz+1)])\n",
        "sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "sr = 1.0 - sa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-b-HmpuyvEd"
      },
      "source": [
        "plt.plot(sr)\n",
        "plt.title(folder_name)\n",
        "plt.xticks(np.arange(0, sz+1,10))\n",
        "plt.ylabel('regularity score Sr(t)')\n",
        "plt.xlabel('frame t')\n",
        "plt.grid(b=1,axis='both')\n",
        "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdogVlnHyo9D"
      },
      "source": [
        "reconstructed_sequences = moveaxis(reconstructed_sequences, 3, 1)\n",
        "sequences = moveaxis(sequences, 3, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irv7-6Tly8wd"
      },
      "source": [
        "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "fps = 10\n",
        "file_name = 'conv2d_ssim_'+folder_name+'.mp4'\n",
        "video_filename = file_name\n",
        "out = cv2.VideoWriter(video_filename, fourcc, fps, (256, 256))\n",
        "\n",
        "\n",
        "THRESH = 80\n",
        "# THRESH_AREA = 50\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  input_frame,output_frame = sequences[i][0].copy(),reconstructed_sequences[i][0].copy()\n",
        "  (score, diff) = ssim(input_frame,output_frame, full=True)\n",
        "  diff = (diff * 255).astype(np.uint8)\n",
        "  ret,thresh = cv2.threshold(diff,THRESH,255,cv2.THRESH_BINARY_INV)\n",
        "  # contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  # contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "\n",
        "  # for c in contours:\n",
        "  #   area = cv2.contourArea(c)\n",
        "  #   if area > THRESH_AREA:\n",
        "  #     x,y,w,h = cv2.boundingRect(c)\n",
        "  #     cv2.rectangle(input_frame, (x, y), (x + w, y + h),1)\n",
        "  gray = cv2.normalize(thresh, None, 255, 0,norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_8U)\n",
        "  gray_3c = cv2.merge([gray, gray,gray])\n",
        "  out.write(gray_3c)\n",
        "\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZMtqUHEz2r2"
      },
      "source": [
        "## **3D Convolutional AE + 2D ConvLSTM & MSE loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf1s7DgW0DVu"
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(227, 227,sequence_size,1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[:,:,cnt,0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    return clips"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIdFE-NZ0MWT"
      },
      "source": [
        "training_set = []\n",
        "i=0\n",
        "for f in sorted(listdir(train_path)):\n",
        "  if fnmatch.fnmatch(f,\"*ped*\"):\n",
        "    for g in listdir(join(train_path,f)):\n",
        "      if fnmatch.fnmatch(g,\"Train\"):\n",
        "        for c in listdir(join(join(train_path,f), g)):\n",
        "          if fnmatch.fnmatch(c,\"Train*\"):\n",
        "            all_frames = []\n",
        "            for j in listdir(join(join(join(train_path,f), g),c)):\n",
        "              if str(j)[-3:] == \"tif\":\n",
        "                img = Image.open(join(join(join(join(train_path,f), g),c), j)).resize((227, 227))\n",
        "                img = np.array(img, dtype=np.float16) / 255.0\n",
        "                all_frames.append(img)                \n",
        "            # get the augmented images from the list of images after applying data augmentation\n",
        "            for stride in range(1, 4):\n",
        "              training_set.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKpQJQw10gCq"
      },
      "source": [
        "input_frm = Input(shape=(227,227,5,1))\n",
        "l1 = Conv3D(128, (11, 11,1), strides=(4,4,1), padding=\"valid\",activation='relu',kernel_initializer=keras.initializers.glorot_normal())(input_frm)\n",
        "l2 = LayerNormalization()(l1)\n",
        "\n",
        "spatial_encoder = Conv3D(64, (5, 5,1), strides=(2,2,1), padding=\"valid\",activation='relu',kernel_initializer=keras.initializers.glorot_normal())(l2)\n",
        "spatial_encoder = LayerNormalization()(spatial_encoder)\n",
        "\n",
        "# # # # #\n",
        "temporal_encoder = ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True,dropout=0.4,recurrent_dropout = 0.3,kernel_initializer=keras.initializers.glorot_normal())(spatial_encoder)\n",
        "l5 = LayerNormalization()(temporal_encoder)\n",
        "\n",
        "l6 = ConvLSTM2D(32, (3, 3), padding=\"same\",return_sequences=True,kernel_initializer=keras.initializers.glorot_normal(),dropout=0.3)(l5)\n",
        "l7 = LayerNormalization()(l6)\n",
        "\n",
        "temporal_decoder = ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True,kernel_initializer=keras.initializers.glorot_normal(),dropout=0.2)(l7)\n",
        "temporal_decoder = LayerNormalization()(temporal_decoder)\n",
        "# # # # #\n",
        "\n",
        "l11 = Conv3DTranspose(128, (5, 5,1), strides=(2,2,1), padding=\"valid\",activation='relu',kernel_initializer=keras.initializers.glorot_normal())(temporal_decoder)\n",
        "l12 = LayerNormalization()(l11)\n",
        "\n",
        "output_frm = Conv3DTranspose(1, (11, 11,1),strides=(4,4,1), activation=\"sigmoid\", padding=\"valid\",kernel_initializer=keras.initializers.glorot_normal())(l12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_-fU54M0mYW"
      },
      "source": [
        "stae_autoencoder = Model(input_frm,output_frm)\n",
        "stae_autoencoder.compile(optimizer=keras.optimizers.Adagrad(learning_rate=0.001), loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq-jxUDW0ta2"
      },
      "source": [
        "history = stae_autoencoder.fit(training_set,training_set,\n",
        "                epochs=25,\n",
        "                batch_size=32,\n",
        "                shuffle=True\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loD_82mo1E5j"
      },
      "source": [
        "sz = 200\n",
        "test = np.zeros(shape=(sz,227, 227,1))\n",
        "cnt = 0\n",
        "for f in sorted(listdir(test_path)):\n",
        "    if str(join(test_path, f))[-3:] == \"tif\":\n",
        "        img = Image.open(join(test_path, f)).resize((227, 227))\n",
        "        img = np.array(img, dtype=np.float16) / 255.0\n",
        "        test[cnt,:, :,0] = img\n",
        "        cnt = cnt + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A58GrhRB1LQz"
      },
      "source": [
        "sz = test.shape[0]-5\n",
        "sequences = np.zeros((sz+1, 227,227,5,1))\n",
        "for i in range(0, sz+1):\n",
        "    clip = np.zeros((227, 227,5,1))\n",
        "    clip = moveaxis(clip, 2, 0)\n",
        "    for j in range(0, 5):\n",
        "        clip[j] = test[i+j,:, :,:]\n",
        "    clip = moveaxis(clip, 0, 2)    \n",
        "    sequences[i] = clip     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MJukcjV1Qeg"
      },
      "source": [
        "reconstructed_sequences = autoencoder.predict(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUUCAwDc7etT"
      },
      "source": [
        "sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "sr = 1.0 - sa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2VzzuDw7f6h"
      },
      "source": [
        "plt.plot(sr)\n",
        "plt.title(folder_name)\n",
        "plt.xticks(np.arange(0, sz+1,10))\n",
        "plt.ylabel('regularity score Sr(t)')\n",
        "plt.xlabel('frame t')\n",
        "plt.grid(b=1,axis='both')\n",
        "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py7jz3FB1SOO"
      },
      "source": [
        "reconstructed_sequences = moveaxis(reconstructed_sequences, 3, 1)\n",
        "reconstructed_sequences = moveaxis(reconstructed_sequences, 4, 2)\n",
        "sequences = moveaxis(sequences, 3, 1)\n",
        "sequences = moveaxis(sequences, 4, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR_Bccby7qeo"
      },
      "source": [
        "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "fps = 10\n",
        "file_name = 'conv2d_mse_'+folder_name+'.mp4'\n",
        "video_filename = file_name\n",
        "out = cv2.VideoWriter(video_filename, fourcc, fps, (256, 256))\n",
        "\n",
        "\n",
        "THRESH = 100\n",
        "THRESH_AREA = 30\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  input_frame,output_frame = sequences[i][0][0].copy(),reconstructed_sequences[i][0][0].copy()\n",
        "  (score, diff) = ssim(input_frame,output_frame, full=True)\n",
        "  diff = (diff * 255).astype(np.uint8)\n",
        "  ret,thresh = cv2.threshold(diff,THRESH,255,cv2.THRESH_BINARY_INV)\n",
        "  contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "\n",
        "  for c in contours:\n",
        "    area = cv2.contourArea(c)\n",
        "    if area > THRESH_AREA:\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "      cv2.rectangle(input_frame, (x, y), (x + w, y + h),1)\n",
        "  gray = cv2.normalize(input_frame, None, 255, 0,norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_8U)\n",
        "  gray_3c = cv2.merge([gray, gray,gray])\n",
        "  out.write(gray_3c)\n",
        "\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}